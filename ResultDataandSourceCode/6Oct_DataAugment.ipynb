{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nisit\\AppData\\Local\\Temp\\ipykernel_33060\\799672564.py:16: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  df.to_excel(file_path, index=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:/Maize_Chainat_C/45Datapoint_Master/ML_analysis/8Oct_Result/hyperparameter_results.xls'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data for the table\n",
    "data = {\n",
    "    \"Model\": [\"Huber\", \"Huber\", \"Huber\", \"M-estimators\", \"M-estimators\", \"Linear Regression\", \"Ridge Regression\", \"Ridge Regression\", \"Ridge Regression\"],\n",
    "    \"Parameter\": [\"alpha\", \"epsilon\", \"max_iter\", \"min_samples\", \"stop_probability\", \"fit_intercept\", \"alpha\", \"fit_intercept\", \"solver\"],\n",
    "    \"Value\": [1, 1.0, 100, 0.7, 0.96, True, 0.615848211066026, True, \"lsqr\"],\n",
    "    \"R^2 Score\": [0.9263, 0.9263, 0.9263, 0.9240, 0.9240, 0.9183, 0.9169, 0.9169, 0.9169]\n",
    "}\n",
    "\n",
    "# Convert data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to .xls format\n",
    "file_path = \"C:/Maize_Chainat_C/45Datapoint_Master/ML_analysis/8Oct_Result/hyperparameter_results.xls\"\n",
    "df.to_excel(file_path, index=False)\n",
    "\n",
    "file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Load the dataset\n",
    "#data = pd.read_csv(\"C:/Maize_Chainat_C/45Datapoint_Master/7FeatureEng_Augment.csv\")\n",
    "#data = pd.read_csv(\"C:/Maize_Chainat_C/45Datapoint_Master/Env_270Dataset.csv\")\n",
    "#data = pd.read_csv(\"C:/Maize_Chainat_C/45Datapoint_Master/16Env_45Point.csv\")\n",
    "data = pd.read_csv(\"C:/Maize_Chainat_C/45Datapoint_Master/ML_analysis/7Oct_270Dataset/5VI_CD_CV_16ENV_270_01.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# Bootstrap sampling to augment the data\n",
    "augmented_data = resample(data, replace=True, n_samples=1000, random_state=42)\n",
    "\n",
    "# Save the augmented data to a new CSV file\n",
    "augmented_data.to_csv(\"C:/Maize_Chainat_C/45Datapoint_Master/ML_analysis/7Oct_270Dataset/Augment5VI_CD_CV_16ENV_1000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.013728</td>\n",
       "      <td>0.117165</td>\n",
       "      <td>0.997748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.023350</td>\n",
       "      <td>0.029442</td>\n",
       "      <td>0.171585</td>\n",
       "      <td>0.995171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.765402</td>\n",
       "      <td>1.181669</td>\n",
       "      <td>1.087046</td>\n",
       "      <td>0.806187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.081996</td>\n",
       "      <td>0.286349</td>\n",
       "      <td>0.986551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huber</td>\n",
       "      <td>0.268496</td>\n",
       "      <td>0.662484</td>\n",
       "      <td>0.813931</td>\n",
       "      <td>0.891342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.290100</td>\n",
       "      <td>0.314948</td>\n",
       "      <td>0.561202</td>\n",
       "      <td>0.948343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>0.937438</td>\n",
       "      <td>1.537310</td>\n",
       "      <td>1.239883</td>\n",
       "      <td>0.747857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.370194</td>\n",
       "      <td>0.604295</td>\n",
       "      <td>0.777364</td>\n",
       "      <td>0.900886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M-estimators</td>\n",
       "      <td>0.300065</td>\n",
       "      <td>0.664407</td>\n",
       "      <td>0.815112</td>\n",
       "      <td>0.891027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Passive Aggressive</td>\n",
       "      <td>0.741806</td>\n",
       "      <td>1.196716</td>\n",
       "      <td>1.093945</td>\n",
       "      <td>0.803720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.065383</td>\n",
       "      <td>0.043501</td>\n",
       "      <td>0.208570</td>\n",
       "      <td>0.992865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.346752</td>\n",
       "      <td>0.623824</td>\n",
       "      <td>0.789825</td>\n",
       "      <td>0.897683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.326516</td>\n",
       "      <td>0.653900</td>\n",
       "      <td>0.808641</td>\n",
       "      <td>0.892750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.017539</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>0.095532</td>\n",
       "      <td>0.998503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model       MAE       MSE      RMSE        R2\n",
       "0             CatBoost  0.065000  0.013728  0.117165  0.997748\n",
       "1        Decision Tree  0.023350  0.029442  0.171585  0.995171\n",
       "2           ElasticNet  0.765402  1.181669  1.087046  0.806187\n",
       "3    Gradient Boosting  0.171800  0.081996  0.286349  0.986551\n",
       "4                Huber  0.268496  0.662484  0.813931  0.891342\n",
       "5                  KNN  0.290100  0.314948  0.561202  0.948343\n",
       "6     Lasso Regression  0.937438  1.537310  1.239883  0.747857\n",
       "7    Linear Regression  0.370194  0.604295  0.777364  0.900886\n",
       "8         M-estimators  0.300065  0.664407  0.815112  0.891027\n",
       "9   Passive Aggressive  0.741806  1.196716  1.093945  0.803720\n",
       "10       Random Forest  0.065383  0.043501  0.208570  0.992865\n",
       "11    Ridge Regression  0.346752  0.623824  0.789825  0.897683\n",
       "12                 SVR  0.326516  0.653900  0.808641  0.892750\n",
       "13             XGBoost  0.017539  0.009126  0.095532  0.998503"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, HuberRegressor, PassiveAggressiveRegressor, RANSACRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "# Load the dataset\n",
    "#data = pd.read_csv(\"C:/Maize_Chainat_C/45Datapoint_Master/5VI_RawData_30Mar_Multiparameter_V8_CV_ALL.csv\")\n",
    "\n",
    "#data = pd.read_csv(\"C:/Maize_Chainat_C/45Datapoint_Master/ML_analysis/6Oct_Result/10Feature_augmented_dataset_01.csv\")\n",
    "\n",
    "# data = pd.read_csv(\"C:/Maize_Chainat_C/45Datapoint_Master/ML_analysis/7Oct_270Dataset/Augment5VI_CD_CV_16ENV_1000.csv\")\n",
    "\n",
    "data = pd.read_csv(\"C:\\Maize_Chainat_C\\45Datapoint_Master\\ML_analysis\\7Oct_270Dataset\\5VI_CD_CV_16ENV_270_01.csv\")\n",
    "\n",
    "# Data Preprocessing\n",
    "# columns_to_drop = ['id', 'Plot_Name']\n",
    "# data = data.drop(columns=columns_to_drop)\n",
    "# data = data.dropna()  # Handle missing values\n",
    "\n",
    "#X = data.drop(columns=[\"Seed\"])\n",
    "#From Top Features selected by Recursive Feature Elimination (RFE) with RandomForestRegressor:\n",
    "# X = data [['Cire_CV',\n",
    "#     'Temperature',\n",
    "#     'Wind speed',\n",
    "#     'SoilHumi',\n",
    "#     'K',\n",
    "#     'Evapotranspiration',\n",
    "#     'P']]\n",
    "\n",
    "# Selecting features RFE\n",
    "X = data[['Cigr_CD','Cire_CD', 'EVI2_CD', 'NDRE_CD', 'NDVI_CD','Cire_CV', 'NDVI_CV', 'Maize_high', 'Humidity', 'Temperature']]\n",
    "\n",
    "\n",
    "# Case2 : selected by Permutation Importance\n",
    "# Case3 : selected by LASSO Regression\n",
    "# Case4 : selected by Recursive Feature Elimination (RFE) with RandomForestRegressor\n",
    "# case5 : \n",
    "\n",
    "\n",
    "y = data['Seed']\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Models Definition\n",
    "models = [\n",
    "    (\"CatBoost\", CatBoostRegressor(verbose=0, random_state=42)),\n",
    "    (\"Decision Tree\", DecisionTreeRegressor(random_state=42)),\n",
    "    (\"ElasticNet\", ElasticNet()),\n",
    "    (\"Gradient Boosting\", GradientBoostingRegressor(random_state=42)),\n",
    "    (\"Huber\", HuberRegressor(max_iter=10000)),\n",
    "    (\"KNN\", KNeighborsRegressor()),\n",
    "    (\"Lasso Regression\", Lasso()),\n",
    "    (\"Linear Regression\", LinearRegression()),\n",
    "    (\"M-estimators\", RANSACRegressor(random_state=42)),\n",
    "    (\"Passive Aggressive\", PassiveAggressiveRegressor(random_state=42)),\n",
    "    (\"Random Forest\", RandomForestRegressor(random_state=42)),\n",
    "    (\"Ridge Regression\", Ridge()),\n",
    "    (\"SVR\", SVR()),\n",
    "    (\"XGBoost\", XGBRegressor(random_state=42))\n",
    "]\n",
    "\n",
    "# Model Evaluation\n",
    "results = []\n",
    "\n",
    "for name, model in models:\n",
    "    # Using a pipeline to ensure that scaling is applied during cross-validation steps as well\n",
    "    pipeline = make_pipeline(StandardScaler(), model)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    results.append([name, mae, mse, rmse, r2])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"MAE\", \"MSE\", \"RMSE\", \"R2\"])\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qgisconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
