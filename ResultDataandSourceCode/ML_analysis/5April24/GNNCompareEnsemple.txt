import pandas as pd
import numpy as np
import torch
import torch_geometric
import torch.optim as optim
from torch_geometric.data import Data
from torch_geometric.loader import DataLoader
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from torch_geometric.nn import GCNConv
from sklearn.linear_model import LinearRegression, Ridge, HuberRegressor, RANSACRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from math import sqrt


# GCN class definition
class GCN(torch.nn.Module):
    def __init__(self, num_node_features, num_classes):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(num_node_features, 16)
        self.conv2 = GCNConv(16, num_classes)
    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        x = torch.relu(x)
        x = self.conv2(x, edge_index)
        return x

# Load and preprocess data
data = pd.read_csv('C:/Maize_Chainat_C/45Datapoint_Master/ML_analysis/7Oct_270Dataset/5VI_CD_CV_16ENV_270_01.csv')
#X = data.drop('Seed', axis=1)  # Features
X = data[['Cire_CD', 'NDRE_CD']]
y = data['Seed']  # Target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Create a similarity graph using cosine similarity
similarity = cosine_similarity(X_scaled)
edges = np.transpose(np.nonzero(similarity > 0.5))  # Adjust threshold as needed

# Convert to tensor
edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()
x = torch.tensor(X_scaled, dtype=torch.float)
y = torch.tensor(y.values, dtype=torch.float).unsqueeze(1)  # Ensure y is the correct shape

# Create PyTorch Geometric data object
data = Data(x=x, edge_index=edge_index, y=y)

# Split indices for training and testing
train_indices, test_indices = train_test_split(np.arange(data.y.size(0)), test_size=0.2, random_state=42)

# Create datasets for given indices
train_dataset = [Data(x=data.x, edge_index=data.edge_index, y=data.y[i]) for i in train_indices]
test_dataset = [Data(x=data.x, edge_index=data.edge_index, y=data.y[i]) for i in test_indices]

# DataLoader for batch processing
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32)

# Define the number of features
num_node_features = x.size(1)

# Choose the model to train
model = GCN(num_node_features, 1)  # Assuming regression, set the number of output features to 1

# Initialize the loss function and optimizer
criterion = torch.nn.MSELoss()  # Use Mean Squared Error Loss for regression
optimizer = optim.Adam(model.parameters(), lr=0.01)

# Training loop
for epoch in range(100):  # number of epochs
    model.train()
    for batch in train_loader:
        optimizer.zero_grad()
        out = model(batch)
        print("Output shape:", out.shape, "Target shape:", batch.y.shape)
        loss = criterion(out, batch.y)
        loss.backward()
        optimizer.step()

    print(f'Epoch {epoch+1}, Loss: {loss.item()}')

# Evaluation loop
predicted = []
actual = []

model.eval()
with torch.no_grad():
    for batch in test_loader:
        out = model(batch)
        # Reshape the output to match the actual labels
        batch_predictions = out.detach().numpy().flatten()
        batch_actual = batch.y.numpy().flatten()
        # Truncate the predictions to match the length of batch_actual
        batch_predictions = batch_predictions[:len(batch_actual)]
        predicted.extend(batch_predictions)
        actual.extend(batch_actual)

# Convert lists to NumPy arrays
predicted = np.array(predicted)
actual = np.array(actual)


#Check Shapes Consistency
print("Predicted shape:", predicted.shape)
print("Actual shape:", actual.shape)


# Calculate MAE, MSE, RMSE, and R2
gnn_mae = mean_absolute_error(actual, predicted)
gnn_mse = mean_squared_error(actual, predicted)
gnn_rmse = np.sqrt(gnn_mse)
gnn_r2 = r2_score(actual, predicted)

# Evaluate GNN model on test set and store metrics
gnn_results = {
    "Method": "GNN",
    "MAE": gnn_mae,
    "MSE": gnn_mse,
    "RMSE": gnn_rmse,
    "R2": gnn_r2
}

#######################################

# Ensemble methods setup and training (from GNN1.txt)
#######################################
# Best hyperparameters obtained from previous runs
best_params = {
    "Huber": {'alpha': 1, 'epsilon': 1.0, 'max_iter': 100},
    "M-estimators": {'min_samples': 0.6, 'stop_probability': 0.97},
    "Linear Regression": {'fit_intercept': True},
    "Ridge Regression": {'alpha': 0.615848211066026, 'fit_intercept': True, 'solver': 'sparse_cg'}
}

# Initialize models with default parameters
default_models = {
    "Huber": HuberRegressor(),
    "M-estimators": RANSACRegressor(),
    "Linear Regression": LinearRegression(),
    "Ridge Regression": Ridge()
}

###########################################

# Initialize models with best parameters
tuned_models = {
    "Huber": HuberRegressor(**best_params["Huber"]),
    "M-estimators": RANSACRegressor(**best_params["M-estimators"]),
    "Linear Regression": LinearRegression(**best_params["Linear Regression"]),
    "Ridge Regression": Ridge(**best_params["Ridge Regression"])
}

# Define ensemble methods with weights
ensemble_methods = {

   "PEnsemble1": {"models": ["Huber", "M-estimators", "Linear Regression", "Ridge Regression"], "weights": [0.5, 0.3, 0.1, 0.1]},  #0.924202
   "PEnsemble2": {"models": ["Huber", "M-estimators", "Linear Regression"], "weights": [0.45, 0.35, 0.2]}, #0.924131
   "PEnsemble3": {"models": ["Huber", "M-estimators", "Ridge Regression"], "weights": [0.45, 0.35, 0.2]}, #0.924017
    "PEnsemble4": {"models": ["Huber", "M-estimators"], "weights": [0.6, 0.4]} #0.925427

}

# Evaluate Ensemble models on test set and store metrics
ensemble_results = []
for method, details in ensemble_methods.items():
    ensemble_predictions = np.zeros(len(y_test))  # Initialize to the same length as y_test
    total_weight = 0

    # Training and predicting with each model in the ensemble
    for model_name, weight in zip(details["models"], details["weights"]):
        model = tuned_models[model_name]
        model.fit(X_train_scaled, y_train)  # Train the model on scaled training data
        predictions = model.predict(X_test_scaled)  # Generate predictions on scaled test data
        ensemble_predictions += weight * predictions  # Weighted sum
        total_weight += weight

    ensemble_predictions /= total_weight  # Normalize by total weight

    # Computing evaluation metrics
    mae = mean_absolute_error(y_test, ensemble_predictions)
    mse = mean_squared_error(y_test, ensemble_predictions)
    rmse = sqrt(mse)
    r2 = r2_score(y_test, ensemble_predictions)

    # Appending results
    ensemble_results.append({
        "Method": method,
        "Model": ", ".join(details["models"]),
        "MAE": mae,
        "MSE": mse,
        "RMSE": rmse,
        "R2": r2
    })

# Combine GNN and ensemble results
all_results = pd.DataFrame([gnn_results] + ensemble_results)
print(all_results)


