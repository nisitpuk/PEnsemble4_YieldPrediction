{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Method                                              Model       MAE  \\\n",
      "0  PEnsemble1  Huber, M-estimators, Linear Regression, Ridge ...  0.308433   \n",
      "1  PEnsemble2             Huber, M-estimators, Linear Regression  0.308890   \n",
      "2  PEnsemble3              Huber, M-estimators, Ridge Regression  0.311677   \n",
      "3  PEnsemble4                                Huber, M-estimators  0.291894   \n",
      "\n",
      "        MSE      RMSE        R2  \n",
      "0  0.531334  0.728926  0.924202  \n",
      "1  0.531836  0.729271  0.924131  \n",
      "2  0.532635  0.729818  0.924017  \n",
      "3  0.522753  0.723016  0.925427  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, HuberRegressor, RANSACRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Maize_Chainat_C/45Datapoint_Master/ML_analysis/7Oct_270Dataset/5VI_CD_CV_16ENV_270_01.csv\")\n",
    "\n",
    "# Features based on SHAP Values\n",
    "X = data[['Cire_CD', 'NDRE_CD']]\n",
    "y = data['Seed']\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=2/3, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#######################################\n",
    "# Best hyperparameters obtained from previous runs\n",
    "best_params = {\n",
    "    \"Huber\": {'alpha': 1, 'epsilon': 1.0, 'max_iter': 100},\n",
    "    \"M-estimators\": {'min_samples': 0.6, 'stop_probability': 0.97},\n",
    "    \"Linear Regression\": {'fit_intercept': True},\n",
    "    \"Ridge Regression\": {'alpha': 0.615848211066026, 'fit_intercept': True, 'solver': 'sparse_cg'}\n",
    "}\n",
    "\n",
    "# Initialize models with default parameters\n",
    "default_models = {\n",
    "    \"Huber\": HuberRegressor(),\n",
    "    \"M-estimators\": RANSACRegressor(),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge()\n",
    "}\n",
    "\n",
    "###########################################\n",
    "\n",
    "# Initialize models with best parameters\n",
    "tuned_models = {\n",
    "    \"Huber\": HuberRegressor(**best_params[\"Huber\"]),\n",
    "    \"M-estimators\": RANSACRegressor(**best_params[\"M-estimators\"]),\n",
    "    \"Linear Regression\": LinearRegression(**best_params[\"Linear Regression\"]),\n",
    "    \"Ridge Regression\": Ridge(**best_params[\"Ridge Regression\"])\n",
    "}\n",
    "\n",
    "# Define ensemble methods with weights\n",
    "ensemble_methods = {\n",
    "\n",
    "   \"PEnsemble1\": {\"models\": [\"Huber\", \"M-estimators\", \"Linear Regression\", \"Ridge Regression\"], \"weights\": [0.5, 0.3, 0.1, 0.1]},  #0.924202\n",
    "   \"PEnsemble2\": {\"models\": [\"Huber\", \"M-estimators\", \"Linear Regression\"], \"weights\": [0.45, 0.35, 0.2]}, #0.924131\n",
    "   \"PEnsemble3\": {\"models\": [\"Huber\", \"M-estimators\", \"Ridge Regression\"], \"weights\": [0.45, 0.35, 0.2]}, #0.924017\n",
    "    \"PEnsemble4\": {\"models\": [\"Huber\", \"M-estimators\"], \"weights\": [0.6, 0.4]} #0.925427\n",
    "\n",
    "}\n",
    " \n",
    "results = []\n",
    "\n",
    "# Compute weighted ensemble predictions\n",
    "for method, details in ensemble_methods.items():\n",
    "    predictions = np.zeros(X_test_scaled.shape[0])\n",
    "    for model_name, weight in zip(details[\"models\"], details[\"weights\"]):\n",
    "        model = tuned_models[model_name]\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        predictions += weight * model.predict(X_test_scaled)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    results.append({\n",
    "        \"Method\": method,\n",
    "        \"Model\": \", \".join(details[\"models\"]),\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "results_df.to_csv(\"C:/Maize_Chainat_C/45Datapoint_Master/ML_analysis/5April24/MAE_R2_of4Ensemble.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, HuberRegressor, RANSACRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:/Maize_Chainat_C/45Datapoint_Master/ML_analysis/7Oct_270Dataset/5VI_CD_CV_16ENV_270_01.csv\")\n",
    "\n",
    "# Features based on SHAP Values\n",
    "X = data[['Cire_CD', 'NDRE_CD']]\n",
    "y = data['Seed']\n",
    "\n",
    "# Splitting the data for ensemble models\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=2/3, random_state=42)\n",
    "\n",
    "# Feature Scaling for ensemble models\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#######################################\n",
    "# Best hyperparameters obtained from previous runs\n",
    "best_params = {\n",
    "    \"Huber\": {'alpha': 1, 'epsilon': 1.0, 'max_iter': 100},\n",
    "    \"M-estimators\": {'min_samples': 0.6, 'stop_probability': 0.97},\n",
    "    \"Linear Regression\": {'fit_intercept': True},\n",
    "    \"Ridge Regression\": {'alpha': 0.615848211066026, 'fit_intercept': True, 'solver': 'sparse_cg'}\n",
    "}\n",
    "\n",
    "# Initialize models with default parameters\n",
    "default_models = {\n",
    "    \"Huber\": HuberRegressor(),\n",
    "    \"M-estimators\": RANSACRegressor(),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge()\n",
    "}\n",
    "\n",
    "###########################################\n",
    "\n",
    "# Initialize models with best parameters\n",
    "tuned_models = {\n",
    "    \"Huber\": HuberRegressor(**best_params[\"Huber\"]),\n",
    "    \"M-estimators\": RANSACRegressor(**best_params[\"M-estimators\"]),\n",
    "    \"Linear Regression\": LinearRegression(**best_params[\"Linear Regression\"]),\n",
    "    \"Ridge Regression\": Ridge(**best_params[\"Ridge Regression\"])\n",
    "}\n",
    "\n",
    "# Define ensemble methods with weights\n",
    "ensemble_methods = {\n",
    "\n",
    "   \"PEnsemble1\": {\"models\": [\"Huber\", \"M-estimators\", \"Linear Regression\", \"Ridge Regression\"], \"weights\": [0.5, 0.3, 0.1, 0.1]},  #0.924202\n",
    "   \"PEnsemble2\": {\"models\": [\"Huber\", \"M-estimators\", \"Linear Regression\"], \"weights\": [0.45, 0.35, 0.2]}, #0.924131\n",
    "   \"PEnsemble3\": {\"models\": [\"Huber\", \"M-estimators\", \"Ridge Regression\"], \"weights\": [0.45, 0.35, 0.2]}, #0.924017\n",
    "    \"PEnsemble4\": {\"models\": [\"Huber\", \"M-estimators\"], \"weights\": [0.6, 0.4]} #0.925427\n",
    "\n",
    "}\n",
    " \n",
    "results = []\n",
    "\n",
    "# Compute weighted ensemble predictions\n",
    "for method, details in ensemble_methods.items():\n",
    "    predictions = np.zeros(X_test_scaled.shape[0])\n",
    "    for model_name, weight in zip(details[\"models\"], details[\"weights\"]):\n",
    "        model = tuned_models[model_name]\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        predictions += weight * model.predict(X_test_scaled)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    results.append({\n",
    "        \"Method\": method,\n",
    "        \"Model\": \", \".join(details[\"models\"]),\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Placeholder for GNN model - Replace with your actual GNN model\n",
    "class YourGNNModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YourGNNModel, self).__init__()\n",
    "        # Define your GNN architecture here\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Define the forward pass\n",
    "        return output\n",
    "\n",
    "# Placeholder for loading and preprocessing data for GNN\n",
    "# Replace with your actual data loading and preprocessing steps for GNN\n",
    "gnn_train_data = None  # Your training graph data\n",
    "gnn_test_data = None   # Your testing graph data\n",
    "\n",
    "gnn_model = YourGNNModel()\n",
    "# Add your code to train the GNN here\n",
    "\n",
    "# Evaluate the GNN - replace with your actual evaluation code\n",
    "gnn_predictions = gnn_model(gnn_test_data)\n",
    "gnn_r2 = r2_score(y_test_gnn, gnn_predictions)  # Replace y_test_gnn with your GNN test labels\n",
    "\n",
    "# Output results for GNN\n",
    "print(f\"GNN Model R2 Score: {gnn_r2}\")\n",
    "\n",
    "# Your code to output ensemble models' results\n",
    "# ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qgisconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
